# -*- coding: utf-8 -*-
"""Fake news prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NP8ScaI_IdvISdtXIxY7swqXtzatZQ63
"""

# =====================================
# Fake News Detection using ISOT Dataset
# =====================================

import pandas as pd
import numpy as np
import re
import nltk

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

from nltk.corpus import stopwords

# Download stopwords (runs once)
nltk.download('stopwords')

# -------------------------------------
# Load ISOT Dataset
# -------------------------------------
fake = pd.read_csv("Fake.csv", on_bad_lines='skip', engine='python')
true = pd.read_csv("True.csv", on_bad_lines='skip', engine='python')

# -------------------------------------
# Add Labels
# -------------------------------------
fake['label'] = 0   # FAKE
true['label'] = 1   # REAL

# -------------------------------------
# Keep Required Columns
# -------------------------------------
fake = fake[['text', 'label']]
true = true[['text', 'label']]

# -------------------------------------
# Combine & Shuffle Dataset
# -------------------------------------
data = pd.concat([fake, true], ignore_index=True)
data = data.sample(frac=1, random_state=42).reset_index(drop=True)

# -------------------------------------
# Text Cleaning Function
# -------------------------------------
def clean_text(text):
    text = text.lower()
    text = re.sub(r'\W', ' ', text)
    text = re.sub(r'\s+', ' ', text)

    words = text.split()
    words = [word for word in words if word not in stopwords.words('english')]

    return ' '.join(words)

# Apply cleaning
data['cleaned_text'] = data['text'].apply(clean_text)

# -------------------------------------
# Train-Test Split
# -------------------------------------
X = data['cleaned_text']
y = data['label']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# -------------------------------------
# TF-IDF Vectorization
# -------------------------------------
vectorizer = TfidfVectorizer(max_features=5000)
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# -------------------------------------
# Train Model
# -------------------------------------
model = LogisticRegression(max_iter=1000)
model.fit(X_train_tfidf, y_train)

# -------------------------------------
# Model Evaluation
# -------------------------------------
y_pred = model.predict(X_test_tfidf)

print("Model Performance")
print("-----------------")
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))

# -------------------------------------
# Prediction Function
# -------------------------------------
def predict_news(news_text):
    cleaned = clean_text(news_text)
    vector = vectorizer.transform([cleaned])
    prediction = model.predict(vector)

    return "REAL News ðŸŸ¢" if prediction[0] == 1 else "FAKE News ðŸ”´"

# -------------------------------------
# Test with Custom Input
# -------------------------------------
print("\nCustom News Prediction")
print("----------------------")

sample_news = input("Enter news text: ")
print("Prediction:", predict_news(sample_news))